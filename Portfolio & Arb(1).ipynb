{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import mpl, plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5ab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load financial data\n",
    "raw = pd.read_csv('http://hilpisch.com/tr_eikon_eod_data.csv', index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e537ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c6a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21171a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log returns for all assets\n",
    "returns = np.log(raw / raw.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb63c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e0b637",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 1: Portfolio Optimization with SciPy\n",
    "\n",
    "**Modern Portfolio Theory (MPT)** seeks to construct portfolios that maximize return for a given level of risk, or minimize risk for a target return.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Expected Return**: Mean historical return of the portfolio\n",
    "- **Portfolio Variance**: Weighted sum of asset variances and covariances\n",
    "- **Sharpe Ratio**: Risk-adjusted return measure (excess return per unit of risk)\n",
    "- **Efficient Frontier**: Set of optimal portfolios offering the best risk/return trade-off\n",
    "\n",
    "We'll use **SciPy's optimization** to find the portfolio weights that maximize the Sharpe ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d65596e",
   "metadata": {},
   "source": [
    "## 1.1 Portfolio Statistics\n",
    "\n",
    "First, let's define functions to calculate portfolio return, volatility, and Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ff8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select assets for portfolio optimization\n",
    "# Using a subset for clarity\n",
    "portfolio_assets = ['AAPL.O', 'MSFT.O', 'INTC.O', 'AMZN.O']\n",
    "print(f\"Portfolio Assets: {portfolio_assets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c4dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract returns for selected assets\n",
    "port_returns = returns[portfolio_assets].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9283c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized statistics\n",
    "mean_returns = port_returns.mean() * 252  # Annualized mean\n",
    "cov_matrix = port_returns.cov() * 252     # Annualized covariance\n",
    "\n",
    "print(\"Annualized Mean Returns:\")\n",
    "print(mean_returns)\n",
    "print(\"\\nAnnualized Covariance Matrix:\")\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af053d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(weights, mean_returns):\n",
    "    \"\"\"\n",
    "    Calculate expected portfolio return.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights : array-like\n",
    "        Asset weights (must sum to 1)\n",
    "    mean_returns : array-like\n",
    "        Expected return for each asset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Portfolio expected return\n",
    "    \"\"\"\n",
    "    return np.sum(weights * mean_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a165e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"\n",
    "    Calculate portfolio volatility (standard deviation).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights : array-like\n",
    "        Asset weights\n",
    "    cov_matrix : DataFrame or array\n",
    "        Covariance matrix of asset returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Portfolio volatility (annualized)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate=0.02):\n",
    "    \"\"\"\n",
    "    Calculate portfolio Sharpe ratio.\n",
    "    \n",
    "    Sharpe Ratio = (Portfolio Return - Risk-Free Rate) / Portfolio Volatility\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    weights : array-like\n",
    "        Asset weights\n",
    "    mean_returns : array-like\n",
    "        Expected returns\n",
    "    cov_matrix : DataFrame or array\n",
    "        Covariance matrix\n",
    "    risk_free_rate : float\n",
    "        Risk-free rate (default 2% annually)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Sharpe ratio\n",
    "    \"\"\"\n",
    "    ret = portfolio_return(weights, mean_returns)\n",
    "    vol = portfolio_volatility(weights, cov_matrix)\n",
    "    return (ret - risk_free_rate) / vol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c0b83c",
   "metadata": {},
   "source": [
    "## 1.2 Test with Equal-Weight Portfolio\n",
    "\n",
    "Before optimization, let's see how an equal-weight portfolio performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e664204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal weights for all assets\n",
    "n_assets = len(portfolio_assets)\n",
    "equal_weights = np.array([1/n_assets] * n_assets)\n",
    "\n",
    "print(f\"Equal Weights: {equal_weights}\")\n",
    "print(f\"Sum of Weights: {equal_weights.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb34bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate equal-weight portfolio statistics\n",
    "eq_return = portfolio_return(equal_weights, mean_returns)\n",
    "eq_volatility = portfolio_volatility(equal_weights, cov_matrix)\n",
    "eq_sharpe = portfolio_sharpe_ratio(equal_weights, mean_returns, cov_matrix)\n",
    "\n",
    "print(f\"Equal-Weight Portfolio:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Expected Return:  {eq_return:.2%}\")\n",
    "print(f\"Volatility:       {eq_volatility:.2%}\")\n",
    "print(f\"Sharpe Ratio:     {eq_sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3101b7a",
   "metadata": {},
   "source": [
    "## 1.3 Optimize for Maximum Sharpe Ratio\n",
    "\n",
    "Now we'll use **SciPy's minimize** function to find the optimal weights.\n",
    "\n",
    "**Optimization Problem:**\n",
    "- **Objective**: Maximize Sharpe ratio (minimize negative Sharpe ratio)\n",
    "- **Constraints**: Weights sum to 1\n",
    "- **Bounds**: Each weight between 0 and 1 (long-only portfolio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e00d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8cd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_sharpe(weights, mean_returns, cov_matrix, risk_free_rate=0.02):\n",
    "    \"\"\"\n",
    "    Negative Sharpe ratio for minimization.\n",
    "    \n",
    "    SciPy's minimize function finds minimum values, so we negate the Sharpe ratio.\n",
    "    \"\"\"\n",
    "    return -portfolio_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cbb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints and bounds\n",
    "constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Weights sum to 1\n",
    "bounds = tuple((0, 1) for _ in range(n_assets))  # Each weight between 0 and 1\n",
    "\n",
    "# Initial guess (equal weights)\n",
    "init_guess = equal_weights\n",
    "\n",
    "print(\"Optimization Setup:\")\n",
    "print(f\"Number of assets: {n_assets}\")\n",
    "print(f\"Constraint: Weights sum to 1\")\n",
    "print(f\"Bounds: Each weight in [0, 1] (long-only)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ea74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimization\n",
    "result = minimize(\n",
    "    negative_sharpe,\n",
    "    init_guess,\n",
    "    args=(mean_returns, cov_matrix),\n",
    "    method='SLSQP',  # Sequential Least Squares Programming\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "# Extract optimal weights\n",
    "optimal_weights = result.x\n",
    "\n",
    "print(\"\\nOptimization Result:\")\n",
    "print(f\"Success: {result.success}\")\n",
    "print(f\"Message: {result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbca647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimal portfolio\n",
    "optimal_portfolio = pd.DataFrame({\n",
    "    'Asset': portfolio_assets,\n",
    "    'Optimal Weight': optimal_weights,\n",
    "    'Equal Weight': equal_weights\n",
    "})\n",
    "optimal_portfolio = optimal_portfolio.sort_values('Optimal Weight', ascending=False)\n",
    "optimal_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658630fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate optimal portfolio statistics\n",
    "opt_return = portfolio_return(optimal_weights, mean_returns)\n",
    "opt_volatility = portfolio_volatility(optimal_weights, cov_matrix)\n",
    "opt_sharpe = portfolio_sharpe_ratio(optimal_weights, mean_returns, cov_matrix)\n",
    "\n",
    "print(f\"Optimal Portfolio (Maximum Sharpe Ratio):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Expected Return:  {opt_return:.2%}\")\n",
    "print(f\"Volatility:       {opt_volatility:.2%}\")\n",
    "print(f\"Sharpe Ratio:     {opt_sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0334f",
   "metadata": {},
   "source": [
    "## 1.4 Compare Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67dd731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Expected Return', 'Volatility', 'Sharpe Ratio'],\n",
    "    'Equal-Weight': [eq_return, eq_volatility, eq_sharpe],\n",
    "    'Optimized': [opt_return, opt_volatility, opt_sharpe]\n",
    "})\n",
    "\n",
    "comparison['Improvement'] = comparison['Optimized'] - comparison['Equal-Weight']\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight allocation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Equal weights\n",
    "axes[0].bar(portfolio_assets, equal_weights, color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('Equal-Weight Portfolio', fontsize=13, pad=15)\n",
    "axes[0].set_ylabel('Weight', fontsize=11)\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Optimal weights\n",
    "axes[1].bar(portfolio_assets, optimal_weights, color='darkgreen', edgecolor='black')\n",
    "axes[1].set_title('Optimal Portfolio (Max Sharpe)', fontsize=13, pad=15)\n",
    "axes[1].set_ylabel('Weight', fontsize=11)\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90293120",
   "metadata": {},
   "source": [
    "## 1.5 Efficient Frontier Visualization\n",
    "\n",
    "The **efficient frontier** shows all optimal portfolios across different risk levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7ca715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random portfolios\n",
    "n_portfolios = 10000\n",
    "results = np.zeros((3, n_portfolios))  # Store return, volatility, Sharpe\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for i in range(n_portfolios):\n",
    "    # Random weights that sum to 1\n",
    "    weights = np.random.random(n_assets)\n",
    "    weights /= weights.sum()\n",
    "    \n",
    "    # Calculate portfolio stats\n",
    "    results[0, i] = portfolio_return(weights, mean_returns)\n",
    "    results[1, i] = portfolio_volatility(weights, cov_matrix)\n",
    "    results[2, i] = portfolio_sharpe_ratio(weights, mean_returns, cov_matrix)\n",
    "\n",
    "print(f\"Generated {n_portfolios} random portfolios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e870485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot efficient frontier\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Scatter plot of random portfolios (color by Sharpe ratio)\n",
    "scatter = plt.scatter(\n",
    "    results[1, :], \n",
    "    results[0, :],\n",
    "    c=results[2, :],\n",
    "    cmap='viridis',\n",
    "    marker='o',\n",
    "    s=10,\n",
    "    alpha=0.5\n",
    ")\n",
    "\n",
    "# Highlight optimal portfolio\n",
    "plt.scatter(\n",
    "    opt_volatility,\n",
    "    opt_return,\n",
    "    c='red',\n",
    "    marker='*',\n",
    "    s=500,\n",
    "    edgecolors='black',\n",
    "    label='Optimal Portfolio',\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "# Highlight equal-weight portfolio\n",
    "plt.scatter(\n",
    "    eq_volatility,\n",
    "    eq_return,\n",
    "    c='orange',\n",
    "    marker='D',\n",
    "    s=200,\n",
    "    edgecolors='black',\n",
    "    label='Equal-Weight Portfolio',\n",
    "    zorder=5\n",
    ")\n",
    "\n",
    "plt.colorbar(scatter, label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility (Risk)', fontsize=12)\n",
    "plt.ylabel('Expected Return', fontsize=12)\n",
    "plt.title('Efficient Frontier - Risk vs Return', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=10, loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae1cd7",
   "metadata": {},
   "source": [
    "### Key Insights from Portfolio Optimization\n",
    "\n",
    "**What we learned:**\n",
    "1. **Diversification isn't always equal-weight** - Optimal allocation depends on:\n",
    "   - Individual asset expected returns\n",
    "   - Asset volatilities\n",
    "   - Correlation structure between assets\n",
    "\n",
    "2. **The efficient frontier** shows the trade-off between risk and return\n",
    "   - Portfolios below the frontier are sub-optimal\n",
    "   - The optimal portfolio maximizes Sharpe ratio (best risk-adjusted return)\n",
    "\n",
    "3. **Practical considerations:**\n",
    "   - Historical data may not predict future returns\n",
    "   - Transaction costs and constraints matter\n",
    "   - Rebalancing frequency affects performance\n",
    "   - Consider adding constraints (sector limits, turnover constraints)\n",
    "\n",
    "**Analysis Questions:**\n",
    "1. Which asset received the highest weight? Why might that be?\n",
    "2. Are any assets completely excluded (weight ≈ 0)? What does this suggest?\n",
    "3. How sensitive is the optimal portfolio to the sample period used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640c602",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 2: Cointegration Testing for Pairs Trading\n",
    "\n",
    "**Cointegration** is a statistical property indicating that two or more time series move together in the long run, even if they drift apart temporarily.\n",
    "\n",
    "**Why it matters for trading:**\n",
    "- Identifies pairs trading opportunities\n",
    "- Mean-reverting spreads can be traded\n",
    "- Statistical arbitrage strategies rely on cointegration\n",
    "- Provides hedge ratios for portfolio construction\n",
    "\n",
    "**Augmented Dickey-Fuller (ADF) Test:**\n",
    "- Tests whether a time series is stationary\n",
    "- For pairs trading: test if the spread between two assets is stationary\n",
    "- **Null hypothesis**: Series has a unit root (non-stationary)\n",
    "- **Alternative**: Series is stationary (mean-reverting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd5ece9",
   "metadata": {},
   "source": [
    "## 2.1 Understanding Stationarity\n",
    "\n",
    "A stationary time series has:\n",
    "- Constant mean over time\n",
    "- Constant variance over time\n",
    "- No trend or seasonality\n",
    "\n",
    "**For pairs trading:** We want the spread to be stationary (mean-reverting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8141f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two assets for cointegration analysis\n",
    "asset1 = 'AAPL.O'\n",
    "asset2 = 'MSFT.O'\n",
    "\n",
    "print(f\"Testing cointegration between {asset1} and {asset2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d221f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract price series\n",
    "prices_pair = raw[[asset1, asset2]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4def68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price series\n",
    "prices_pair.plot(figsize=(12, 6), linewidth=2)\n",
    "plt.title(f'Price Series: {asset1} vs {asset2}', fontsize=14, pad=20)\n",
    "plt.ylabel('Price', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Question: Do these prices appear to move together?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81545305",
   "metadata": {},
   "source": [
    "## 2.2 Perform Linear Regression\n",
    "\n",
    "First, we need to find the hedge ratio (beta) between the two assets using linear regression.\n",
    "\n",
    "The hedge ratio tells us how many units of asset2 to short for each unit of asset1 we long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074b17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af20fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression: asset1 = alpha + beta * asset2\n",
    "X = prices_pair[asset2].values.reshape(-1, 1)\n",
    "y = prices_pair[asset1].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "hedge_ratio = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "\n",
    "print(f\"Linear Regression Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Hedge Ratio (Beta): {hedge_ratio:.4f}\")\n",
    "print(f\"Intercept (Alpha):  {intercept:.4f}\")\n",
    "print(f\"\\nInterpretation: For every $1 change in {asset2},\")\n",
    "print(f\"{asset1} changes by ${hedge_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e449d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(prices_pair[asset2], prices_pair[asset1], alpha=0.3, s=10)\n",
    "plt.plot(\n",
    "    prices_pair[asset2],\n",
    "    intercept + hedge_ratio * prices_pair[asset2],\n",
    "    'r-',\n",
    "    linewidth=2,\n",
    "    label=f'Regression Line (β={hedge_ratio:.3f})'\n",
    ")\n",
    "plt.xlabel(f'{asset2} Price', fontsize=12)\n",
    "plt.ylabel(f'{asset1} Price', fontsize=12)\n",
    "plt.title('Price Relationship & Hedge Ratio', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2304dce1",
   "metadata": {},
   "source": [
    "## 2.3 Calculate Spread\n",
    "\n",
    "The **spread** is the residual from the regression:\n",
    "\n",
    "**Spread = asset1 - (hedge_ratio × asset2)**\n",
    "\n",
    "If the assets are cointegrated, this spread should be stationary (mean-reverting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spread\n",
    "prices_pair['spread'] = prices_pair[asset1] - hedge_ratio * prices_pair[asset2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize spread\n",
    "prices_pair['spread'].plot(figsize=(12, 6), linewidth=1.5, color='purple')\n",
    "plt.axhline(prices_pair['spread'].mean(), color='red', linestyle='--', label='Mean')\n",
    "plt.axhline(\n",
    "    prices_pair['spread'].mean() + prices_pair['spread'].std(),\n",
    "    color='orange',\n",
    "    linestyle='--',\n",
    "    alpha=0.7,\n",
    "    label='+1 Std Dev'\n",
    ")\n",
    "plt.axhline(\n",
    "    prices_pair['spread'].mean() - prices_pair['spread'].std(),\n",
    "    color='orange',\n",
    "    linestyle='--',\n",
    "    alpha=0.7,\n",
    "    label='-1 Std Dev'\n",
    ")\n",
    "plt.title(f'Spread: {asset1} - {hedge_ratio:.3f} × {asset2}', fontsize=14, pad=20)\n",
    "plt.ylabel('Spread Value', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Visual test: Does the spread oscillate around the mean?\")\n",
    "print(\"This suggests potential mean-reversion (stationarity).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7dddf",
   "metadata": {},
   "source": [
    "## 2.4 Augmented Dickey-Fuller (ADF) Test\n",
    "\n",
    "Now we formally test if the spread is stationary using the ADF test.\n",
    "\n",
    "**Interpretation:**\n",
    "- **p-value < 0.05**: Reject null hypothesis → Spread is stationary → Cointegration exists! ✓\n",
    "- **p-value ≥ 0.05**: Cannot reject null → Spread is non-stationary → No cointegration ✗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aaaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test on a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : array-like\n",
    "        Time series to test\n",
    "    name : str\n",
    "        Name of the series for display\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Test results including test statistic, p-value, and critical values\n",
    "    \"\"\"\n",
    "    result = adfuller(series, autolag='AIC')\n",
    "    \n",
    "    print(f'ADF Test Results for {name}')\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f'ADF Test Statistic:    {result[0]:.4f}')\n",
    "    print(f'p-value:               {result[1]:.4f}')\n",
    "    print(f'Number of Lags Used:   {result[2]}')\n",
    "    print(f'Number of Observations: {result[3]}')\n",
    "    print(f'\\nCritical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'  {key}: {value:.4f}')\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    if result[1] < 0.05:\n",
    "        print(f'✓ RESULT: Reject null hypothesis (p-value = {result[1]:.4f})')\n",
    "        print(f'✓ The series is STATIONARY (mean-reverting)')\n",
    "        print(f'✓ Cointegration likely exists!')\n",
    "    else:\n",
    "        print(f'✗ RESULT: Cannot reject null hypothesis (p-value = {result[1]:.4f})')\n",
    "        print(f'✗ The series is NON-STATIONARY')\n",
    "        print(f'✗ No evidence of cointegration')\n",
    "    \n",
    "    return {\n",
    "        'test_statistic': result[0],\n",
    "        'p_value': result[1],\n",
    "        'lags_used': result[2],\n",
    "        'n_obs': result[3],\n",
    "        'critical_values': result[4],\n",
    "        'is_stationary': result[1] < 0.05\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the spread for stationarity\n",
    "adf_result = adf_test(prices_pair['spread'].dropna(), name='Spread')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f4843",
   "metadata": {},
   "source": [
    "## 2.5 Test Individual Assets (Comparison)\n",
    "\n",
    "For comparison, let's test if the individual asset prices are stationary.\n",
    "\n",
    "**Expected:** Individual stock prices are typically non-stationary (they have trends)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test asset1\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "adf_result1 = adf_test(prices_pair[asset1], name=asset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d33df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test asset2\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "adf_result2 = adf_test(prices_pair[asset2], name=asset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8f17c",
   "metadata": {},
   "source": [
    "### Key Insight\n",
    "\n",
    "**Cointegration vs Correlation:**\n",
    "- **Correlation** measures linear relationship at a point in time\n",
    "- **Cointegration** measures long-run equilibrium relationship\n",
    "- Two assets can be cointegrated but have low short-term correlation\n",
    "- Cointegration is more useful for pairs trading than correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ec316",
   "metadata": {},
   "source": [
    "## 2.6 Test Multiple Pairs\n",
    "\n",
    "Let's test cointegration across multiple asset pairs to find the best candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select assets for pairwise testing\n",
    "test_assets = ['AAPL.O', 'MSFT.O', 'INTC.O', 'AMZN.O', 'GOOGL.O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to test all pairs\n",
    "def test_all_pairs(assets, prices_data):\n",
    "    \"\"\"\n",
    "    Test cointegration for all possible pairs.\n",
    "    \n",
    "    Returns DataFrame with test results for each pair.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(len(assets)):\n",
    "        for j in range(i+1, len(assets)):\n",
    "            asset_i = assets[i]\n",
    "            asset_j = assets[j]\n",
    "            \n",
    "            # Get prices\n",
    "            pair_data = prices_data[[asset_i, asset_j]].dropna()\n",
    "            \n",
    "            # Run regression\n",
    "            X = pair_data[asset_j].values.reshape(-1, 1)\n",
    "            y = pair_data[asset_i].values\n",
    "            \n",
    "            reg = LinearRegression()\n",
    "            reg.fit(X, y)\n",
    "            \n",
    "            hedge = reg.coef_[0]\n",
    "            \n",
    "            # Calculate spread\n",
    "            spread = pair_data[asset_i] - hedge * pair_data[asset_j]\n",
    "            \n",
    "            # ADF test\n",
    "            adf_result = adfuller(spread, autolag='AIC')\n",
    "            \n",
    "            results.append({\n",
    "                'Asset 1': asset_i,\n",
    "                'Asset 2': asset_j,\n",
    "                'Hedge Ratio': hedge,\n",
    "                'ADF Statistic': adf_result[0],\n",
    "                'p-value': adf_result[1],\n",
    "                'Is Cointegrated': adf_result[1] < 0.05\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all pairs\n",
    "cointegration_results = test_all_pairs(test_assets, raw)\n",
    "cointegration_results = cointegration_results.sort_values('p-value')\n",
    "cointegration_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a38791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize findings\n",
    "n_pairs = len(cointegration_results)\n",
    "n_cointegrated = cointegration_results['Is Cointegrated'].sum()\n",
    "\n",
    "print(f\"Cointegration Testing Summary:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total pairs tested:      {n_pairs}\")\n",
    "print(f\"Cointegrated pairs:      {n_cointegrated}\")\n",
    "print(f\"Percentage cointegrated: {n_cointegrated/n_pairs:.1%}\")\n",
    "print(f\"\\nBest pair (lowest p-value):\")\n",
    "best_pair = cointegration_results.iloc[0]\n",
    "print(f\"  {best_pair['Asset 1']} & {best_pair['Asset 2']}\")\n",
    "print(f\"  p-value: {best_pair['p-value']:.4f}\")\n",
    "print(f\"  Hedge ratio: {best_pair['Hedge Ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31884d9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART 3: Portfolio Beta & Z-Scores\n",
    "\n",
    "**Portfolio Beta** measures a portfolio's sensitivity to market movements.\n",
    "\n",
    "**Z-Score** measures how many standard deviations a value is from the mean - crucial for pairs trading signals.\n",
    "\n",
    "These metrics are essential for:\n",
    "- Risk management (market exposure)\n",
    "- Position sizing\n",
    "- Trading signal generation\n",
    "- Portfolio hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b81b00",
   "metadata": {},
   "source": [
    "## 3.1 Calculate Portfolio Beta\n",
    "\n",
    "**Beta (β)** measures systematic risk:\n",
    "- **β = 1**: Portfolio moves with the market\n",
    "- **β > 1**: Portfolio is more volatile than market (aggressive)\n",
    "- **β < 1**: Portfolio is less volatile than market (defensive)\n",
    "- **β < 0**: Portfolio moves opposite to market (hedged)\n",
    "\n",
    "**Formula:** β = Cov(Portfolio, Market) / Var(Market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SPY (S&P 500 ETF) as market proxy\n",
    "# We'll use .SPX (S&P 500 Index) from our data\n",
    "market_symbol = '.SPX'\n",
    "\n",
    "# Check if market index is available\n",
    "if market_symbol in raw.columns:\n",
    "    market_prices = raw[market_symbol]\n",
    "    market_returns = np.log(market_prices / market_prices.shift(1)).dropna()\n",
    "    print(f\"Using {market_symbol} as market benchmark\")\n",
    "else:\n",
    "    # Fallback: use an equity instrument\n",
    "    market_symbol = 'AAPL.O'\n",
    "    market_prices = raw[market_symbol]\n",
    "    market_returns = np.log(market_prices / market_prices.shift(1)).dropna()\n",
    "    print(f\"Using {market_symbol} as market proxy (SPX not available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create portfolio returns using optimal weights\n",
    "portfolio_returns = (port_returns * optimal_weights).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7106d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align portfolio and market returns\n",
    "aligned_data = pd.DataFrame({\n",
    "    'portfolio': portfolio_returns,\n",
    "    'market': market_returns\n",
    "}).dropna()\n",
    "\n",
    "aligned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecaa1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_beta(portfolio_returns, market_returns):\n",
    "    \"\"\"\n",
    "    Calculate portfolio beta.\n",
    "    \n",
    "    Beta = Covariance(Portfolio, Market) / Variance(Market)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    portfolio_returns : array-like\n",
    "        Portfolio return series\n",
    "    market_returns : array-like\n",
    "        Market return series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Beta, correlation, and related statistics\n",
    "    \"\"\"\n",
    "    # Calculate covariance and variance\n",
    "    cov_matrix = np.cov(portfolio_returns, market_returns)\n",
    "    covariance = cov_matrix[0, 1]\n",
    "    market_variance = cov_matrix[1, 1]\n",
    "    \n",
    "    # Calculate beta\n",
    "    beta = covariance / market_variance\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation = np.corrcoef(portfolio_returns, market_returns)[0, 1]\n",
    "    \n",
    "    # Calculate alpha (excess return not explained by market)\n",
    "    # Using simple regression\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    X = market_returns.values.reshape(-1, 1)\n",
    "    y = portfolio_returns.values\n",
    "    \n",
    "    reg = LinearRegression()\n",
    "    reg.fit(X, y)\n",
    "    \n",
    "    alpha = reg.intercept_ * 252  # Annualized\n",
    "    \n",
    "    return {\n",
    "        'beta': beta,\n",
    "        'correlation': correlation,\n",
    "        'alpha': alpha,\n",
    "        'covariance': covariance,\n",
    "        'market_variance': market_variance\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550d799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate beta for optimal portfolio\n",
    "beta_stats = calculate_beta(aligned_data['portfolio'], aligned_data['market'])\n",
    "\n",
    "print(f\"Portfolio Beta Analysis:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Beta:                {beta_stats['beta']:.4f}\")\n",
    "print(f\"Correlation:         {beta_stats['correlation']:.4f}\")\n",
    "print(f\"Alpha (annualized):  {beta_stats['alpha']:.2%}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "if beta_stats['beta'] > 1:\n",
    "    print(f\"  Portfolio is MORE volatile than the market\")\n",
    "    print(f\"  A 1% market move → {beta_stats['beta']:.2%} portfolio move (expected)\")\n",
    "elif beta_stats['beta'] < 1 and beta_stats['beta'] > 0:\n",
    "    print(f\"  Portfolio is LESS volatile than the market\")\n",
    "    print(f\"  A 1% market move → {beta_stats['beta']:.2%} portfolio move (expected)\")\n",
    "else:\n",
    "    print(f\"  Portfolio has negative or zero market correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc564151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio vs market relationship\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(aligned_data['market'], aligned_data['portfolio'], alpha=0.3, s=10)\n",
    "\n",
    "# Add regression line\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = aligned_data['market'].values.reshape(-1, 1)\n",
    "y = aligned_data['portfolio'].values\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "\n",
    "plt.plot(\n",
    "    aligned_data['market'],\n",
    "    reg.predict(X),\n",
    "    'r-',\n",
    "    linewidth=2,\n",
    "    label=f'β = {beta_stats[\"beta\"]:.3f}'\n",
    ")\n",
    "\n",
    "plt.xlabel('Market Returns', fontsize=12)\n",
    "plt.ylabel('Portfolio Returns', fontsize=12)\n",
    "plt.title('Portfolio Beta - Relationship with Market', fontsize=14, pad=20)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3c974",
   "metadata": {},
   "source": [
    "## 3.2 Calculate Z-Scores for Pairs Trading\n",
    "\n",
    "**Z-Score** measures how far the spread has deviated from its mean in terms of standard deviations.\n",
    "\n",
    "**Formula:** Z = (Spread - Mean) / Std Dev\n",
    "\n",
    "**Trading signals:**\n",
    "- **Z > +2**: Spread is too high → SHORT the spread (short asset1, long asset2)\n",
    "- **Z < -2**: Spread is too low → LONG the spread (long asset1, short asset2)\n",
    "- **|Z| < 0.5**: Spread near mean → CLOSE positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf076f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best cointegrated pair from earlier\n",
    "best_pair = cointegration_results.iloc[0]\n",
    "asset1_pair = best_pair['Asset 1']\n",
    "asset2_pair = best_pair['Asset 2']\n",
    "hedge_ratio_pair = best_pair['Hedge Ratio']\n",
    "\n",
    "print(f\"Analyzing pair: {asset1_pair} & {asset2_pair}\")\n",
    "print(f\"Hedge Ratio: {hedge_ratio_pair:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prices and calculate spread\n",
    "pair_prices = raw[[asset1_pair, asset2_pair]].dropna()\n",
    "pair_prices['spread'] = pair_prices[asset1_pair] - hedge_ratio_pair * pair_prices[asset2_pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5879bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscore(series, window=20):\n",
    "    \"\"\"\n",
    "    Calculate rolling z-score.\n",
    "    \n",
    "    Z-score = (Value - Rolling Mean) / Rolling Std Dev\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : array-like\n",
    "        Time series data\n",
    "    window : int\n",
    "        Rolling window size\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Series : Z-scores\n",
    "    \"\"\"\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    rolling_std = series.rolling(window=window).std()\n",
    "    zscore = (series - rolling_mean) / rolling_std\n",
    "    return zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores with different windows\n",
    "pair_prices['zscore_20'] = calculate_zscore(pair_prices['spread'], window=20)\n",
    "pair_prices['zscore_60'] = calculate_zscore(pair_prices['spread'], window=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd1da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_prices[['spread', 'zscore_20', 'zscore_60']].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc94e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize z-scores with trading signals\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot 1: Spread\n",
    "axes[0].plot(pair_prices.index, pair_prices['spread'], linewidth=1, color='purple')\n",
    "axes[0].axhline(pair_prices['spread'].mean(), color='black', linestyle='--', label='Mean')\n",
    "axes[0].set_ylabel('Spread Value', fontsize=11)\n",
    "axes[0].set_title(f'Spread: {asset1_pair} - {hedge_ratio_pair:.3f} × {asset2_pair}', fontsize=13)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Z-Scores with trading signals\n",
    "axes[1].plot(pair_prices.index, pair_prices['zscore_20'], linewidth=1, label='Z-Score (20-day)', color='blue')\n",
    "axes[1].axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "axes[1].axhline(2, color='red', linestyle='--', linewidth=1.5, label='Overbought (+2σ)')\n",
    "axes[1].axhline(-2, color='green', linestyle='--', linewidth=1.5, label='Oversold (-2σ)')\n",
    "axes[1].axhline(1, color='orange', linestyle=':', alpha=0.7)\n",
    "axes[1].axhline(-1, color='orange', linestyle=':', alpha=0.7)\n",
    "axes[1].fill_between(pair_prices.index, 2, 3, alpha=0.2, color='red')\n",
    "axes[1].fill_between(pair_prices.index, -2, -3, alpha=0.2, color='green')\n",
    "axes[1].set_ylabel('Z-Score', fontsize=11)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_title('Z-Score with Trading Signals', fontsize=13)\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e58cae",
   "metadata": {},
   "source": [
    "## 3.3 Generate Trading Signals\n",
    "\n",
    "Create actual entry/exit signals based on z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define signal thresholds\n",
    "entry_threshold = 2.0  # Enter when |z| > 2\n",
    "exit_threshold = 0.5   # Exit when |z| < 0.5\n",
    "\n",
    "# Generate signals\n",
    "pair_prices['signal'] = 0\n",
    "\n",
    "# Long spread signal (z-score < -2): Long asset1, Short asset2\n",
    "pair_prices.loc[pair_prices['zscore_20'] < -entry_threshold, 'signal'] = 1\n",
    "\n",
    "# Short spread signal (z-score > 2): Short asset1, Long asset2\n",
    "pair_prices.loc[pair_prices['zscore_20'] > entry_threshold, 'signal'] = -1\n",
    "\n",
    "# Maintain position until exit threshold\n",
    "pair_prices['position'] = pair_prices['signal'].replace(0, np.nan).fillna(method='ffill').fillna(0)\n",
    "\n",
    "# Exit when z-score crosses exit threshold\n",
    "exit_condition = np.abs(pair_prices['zscore_20']) < exit_threshold\n",
    "pair_prices.loc[exit_condition, 'position'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16400d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count signals\n",
    "signal_counts = pair_prices['signal'].value_counts()\n",
    "print(f\"Trading Signals Generated:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Long spread signals:   {signal_counts.get(1, 0)}\")\n",
    "print(f\"Short spread signals:  {signal_counts.get(-1, 0)}\")\n",
    "print(f\"Neutral periods:       {signal_counts.get(0, 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate strategy returns\n",
    "pair_returns = pair_prices[[asset1_pair, asset2_pair]].pct_change()\n",
    "\n",
    "# Spread return = return on asset1 - hedge_ratio * return on asset2\n",
    "pair_prices['spread_return'] = (\n",
    "    pair_returns[asset1_pair] - hedge_ratio_pair * pair_returns[asset2_pair]\n",
    ")\n",
    "\n",
    "# Strategy return = position * spread_return\n",
    "pair_prices['strategy_return'] = pair_prices['position'].shift(1) * pair_prices['spread_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58523f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics\n",
    "cumulative_strategy = (1 + pair_prices['strategy_return'].fillna(0)).cumprod()\n",
    "total_return = cumulative_strategy.iloc[-1] - 1\n",
    "\n",
    "# Sharpe ratio\n",
    "sharpe = (pair_prices['strategy_return'].mean() / pair_prices['strategy_return'].std()) * np.sqrt(252)\n",
    "\n",
    "# Max drawdown\n",
    "cummax = cumulative_strategy.cummax()\n",
    "drawdown = (cumulative_strategy - cummax) / cummax\n",
    "max_drawdown = drawdown.min()\n",
    "\n",
    "print(f\"Pairs Trading Strategy Performance:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total Return:     {total_return:.2%}\")\n",
    "print(f\"Sharpe Ratio:     {sharpe:.3f}\")\n",
    "print(f\"Max Drawdown:     {max_drawdown:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4633f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "cumulative_strategy.plot(linewidth=2, color='darkgreen')\n",
    "plt.title('Pairs Trading Strategy - Cumulative Returns', fontsize=14, pad=20)\n",
    "plt.ylabel('Cumulative Return', fontsize=12)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb7cef",
   "metadata": {},
   "source": [
    "## 3.4 Z-Score Statistics\n",
    "\n",
    "Analyze the distribution and properties of z-scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-score statistics\n",
    "zscore_stats = pair_prices['zscore_20'].dropna().describe()\n",
    "print(\"Z-Score Statistics:\")\n",
    "print(zscore_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot z-score distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(pair_prices['zscore_20'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(0, color='black', linestyle='--', linewidth=1.5, label='Mean (0)')\n",
    "axes[0].axvline(2, color='red', linestyle='--', linewidth=1.5, label='+2σ')\n",
    "axes[0].axvline(-2, color='green', linestyle='--', linewidth=1.5, label='-2σ')\n",
    "axes[0].set_xlabel('Z-Score', fontsize=11)\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[0].set_title('Z-Score Distribution', fontsize=13)\n",
    "axes[0].legend(fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Time series of absolute z-scores\n",
    "axes[1].plot(pair_prices.index, np.abs(pair_prices['zscore_20']), linewidth=1, color='purple', alpha=0.6)\n",
    "axes[1].axhline(2, color='red', linestyle='--', linewidth=1.5, label='Entry Threshold (2σ)')\n",
    "axes[1].axhline(0.5, color='orange', linestyle='--', linewidth=1.5, label='Exit Threshold (0.5σ)')\n",
    "axes[1].set_ylabel('|Z-Score|', fontsize=11)\n",
    "axes[1].set_xlabel('Date', fontsize=11)\n",
    "axes[1].set_title('Absolute Z-Score Over Time', fontsize=13)\n",
    "axes[1].legend(fontsize=9)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of time at different z-score levels\n",
    "zscore_abs = np.abs(pair_prices['zscore_20'].dropna())\n",
    "\n",
    "pct_extreme = (zscore_abs > 2).sum() / len(zscore_abs) * 100\n",
    "pct_moderate = ((zscore_abs > 1) & (zscore_abs <= 2)).sum() / len(zscore_abs) * 100\n",
    "pct_normal = (zscore_abs <= 1).sum() / len(zscore_abs) * 100\n",
    "\n",
    "print(f\"Z-Score Time Distribution:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"|Z| > 2 (Extreme):     {pct_extreme:.1f}%\")\n",
    "print(f\"1 < |Z| ≤ 2 (Moderate): {pct_moderate:.1f}%\")\n",
    "print(f\"|Z| ≤ 1 (Normal):      {pct_normal:.1f}%\")\n",
    "print(f\"\\nTrading opportunities (|Z| > 2) occur {pct_extreme:.1f}% of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a4b85",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Takeaways\n",
    "\n",
    "### Portfolio Optimization:\n",
    "1. **Mean-Variance Optimization** - Mathematical framework for optimal allocation\n",
    "   - Maximizes Sharpe ratio (risk-adjusted return)\n",
    "   - Considers correlations between assets\n",
    "   - SciPy provides powerful optimization tools\n",
    "   \n",
    "2. **Efficient Frontier** - Visualizes risk-return trade-offs\n",
    "   - Only portfolios on the frontier are optimal\n",
    "   - Different risk preferences → different optimal portfolios\n",
    "   - Real-world constraints matter (transaction costs, limits)\n",
    "\n",
    "3. **Equal-weight vs Optimized** - Optimization can improve performance\n",
    "   - But: based on historical data (may not predict future)\n",
    "   - Requires periodic rebalancing\n",
    "   - Consider estimation error and overfitting\n",
    "\n",
    "### Cointegration Testing:\n",
    "1. **ADF Test** - Statistical test for mean-reversion\n",
    "   - Tests if spread is stationary\n",
    "   - p-value < 0.05 indicates cointegration\n",
    "   - More robust than correlation for pairs trading\n",
    "   \n",
    "2. **Hedge Ratio** - Determines proper position sizes\n",
    "   - From linear regression\n",
    "   - Creates a mean-reverting spread\n",
    "   - Should be monitored and updated\n",
    "\n",
    "3. **Practical Considerations**\n",
    "   - Cointegration can break down over time\n",
    "   - Transaction costs matter for high-frequency trading\n",
    "   - Need sufficient capital to hold both legs\n",
    "\n",
    "### Portfolio Beta & Z-Scores:\n",
    "1. **Beta** - Measures market exposure\n",
    "   - β > 1: Aggressive (amplifies market moves)\n",
    "   - β < 1: Defensive (dampens market moves)\n",
    "   - Critical for risk management and hedging\n",
    "   \n",
    "2. **Z-Scores** - Trading signal generation\n",
    "   - Standardizes deviations from mean\n",
    "   - Entry signals at ±2 standard deviations\n",
    "   - Exit signals when returning to mean\n",
    "   \n",
    "3. **Applications**\n",
    "   - Beta: Portfolio hedging, risk budgeting\n",
    "   - Z-scores: Pairs trading, mean reversion strategies\n",
    "   - Both: Essential risk management tools\n",
    "\n",
    "### Best Practices:\n",
    "✅ **DO:**\n",
    "- Update optimization inputs regularly\n",
    "- Test multiple cointegration periods\n",
    "- Monitor beta drift over time\n",
    "- Use multiple confirmation signals\n",
    "- Account for transaction costs\n",
    "\n",
    "❌ **DON'T:**\n",
    "- Assume historical patterns persist forever\n",
    "- Over-optimize on in-sample data\n",
    "- Ignore regime changes\n",
    "- Trade pairs without stop-losses\n",
    "- Neglect position sizing\n",
    "\n",
    "### Integration:\n",
    "These three techniques work together:\n",
    "- **Optimization** → Find best portfolio weights\n",
    "- **Cointegration** → Identify pairs for hedging or arbitrage\n",
    "- **Beta & Z-scores** → Manage risk and generate signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22890b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 Student Assignment\n",
    "\n",
    "Complete the following tasks to apply portfolio optimization, cointegration testing, and analytics.\n",
    "\n",
    "**Expected Time**: 90-120 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b470e17",
   "metadata": {},
   "source": [
    "## Task 1: Constrained Portfolio Optimization\n",
    "\n",
    "**Objective:** Add realistic constraints to portfolio optimization and compare results.\n",
    "\n",
    "Implement at least TWO of the following constraint scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ece58",
   "metadata": {},
   "source": [
    "### Option A: Sector/Asset Limits\n",
    "\n",
    "Add maximum weight constraints (e.g., no asset > 40% of portfolio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement optimization with individual asset constraints\n",
    "# Hint: Modify bounds parameter or add additional constraints\n",
    "# Example: No asset weight > 0.40 (40%)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdddfca",
   "metadata": {},
   "source": [
    "### Option B: Long-Short Portfolio\n",
    "\n",
    "Allow short positions (negative weights) within limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c535677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement long-short optimization\n",
    "# Hint: Change bounds to allow negative weights (e.g., -0.5 to 1.0)\n",
    "# Add constraint that absolute weights sum to 1.0\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7dcc55",
   "metadata": {},
   "source": [
    "### Option C: Minimum Weight Requirements\n",
    "\n",
    "Require minimum allocation to each asset (e.g., at least 10% per asset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement optimization with minimum weights\n",
    "# Hint: Set bounds like (0.10, 0.50) instead of (0, 1)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare all portfolio variants\n",
    "# Create comparison table showing:\n",
    "# - Weights for each portfolio\n",
    "# - Expected return\n",
    "# - Volatility  \n",
    "# - Sharpe ratio\n",
    "# - Sum of absolute weights (for long-short)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0115c444",
   "metadata": {},
   "source": [
    "### Analysis Questions for Task 1\n",
    "\n",
    "**TODO: Write your analysis here**\n",
    "\n",
    "1. How do constraints affect the optimal portfolio?\n",
    "2. Which constrained portfolio would you prefer for real trading? Why?\n",
    "3. What's the trade-off between constraints and performance?\n",
    "4. For long-short portfolios: How does allowing shorts change the efficient frontier?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb3242",
   "metadata": {},
   "source": [
    "## Task 2: Rolling Cointegration Analysis\n",
    "\n",
    "**Objective:** Analyze how cointegration relationships change over time.\n",
    "\n",
    "Test if cointegrated pairs remain stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80868b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement rolling cointegration test\n",
    "# 1. Select a cointegrated pair from earlier analysis\n",
    "# 2. Define rolling windows (e.g., 252 trading days = 1 year)\n",
    "# 3. Calculate p-values for each window\n",
    "# 4. Track hedge ratio over time\n",
    "# 5. Visualize results\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0945ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations\n",
    "# Plot 1: Rolling p-values over time (with 0.05 threshold line)\n",
    "# Plot 2: Rolling hedge ratio over time\n",
    "# Plot 3: Percentage of time pair is cointegrated (by year or quarter)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da4055",
   "metadata": {},
   "source": [
    "### Analysis Questions for Task 2\n",
    "\n",
    "**TODO: Write your analysis here**\n",
    "\n",
    "1. Is the cointegration relationship stable over time?\n",
    "2. During which periods did cointegration break down?\n",
    "3. How much does the hedge ratio vary? Should you update it regularly?\n",
    "4. What market conditions might cause cointegration to fail?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577f1a1",
   "metadata": {},
   "source": [
    "## Task 3: Enhanced Pairs Trading Strategy\n",
    "\n",
    "**Objective:** Improve the basic pairs trading strategy with additional features.\n",
    "\n",
    "Implement at least TWO enhancements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af01261",
   "metadata": {},
   "source": [
    "### Enhancement A: Dynamic Thresholds\n",
    "\n",
    "Use different entry/exit thresholds based on market conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement dynamic thresholds\n",
    "# Ideas:\n",
    "# - Wider thresholds during high volatility periods\n",
    "# - Asymmetric entry/exit thresholds\n",
    "# - Adaptive thresholds based on recent z-score distribution\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68177f",
   "metadata": {},
   "source": [
    "### Enhancement B: Stop-Loss & Take-Profit\n",
    "\n",
    "Add risk management rules to limit losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement stop-loss and take-profit\n",
    "# - Exit position if z-score reaches extreme level (e.g., |z| > 3.5)\n",
    "# - Exit position if spread moves against you beyond threshold\n",
    "# - Implement maximum holding period\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff5886",
   "metadata": {},
   "source": [
    "### Enhancement C: Position Sizing\n",
    "\n",
    "Vary position size based on z-score magnitude or confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d221b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement position sizing\n",
    "# - Larger positions for more extreme z-scores\n",
    "# - Consider recent strategy performance (scale down after losses)\n",
    "# - Account for spread volatility\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare strategy variants\n",
    "# Backtest and compare:\n",
    "# - Original strategy\n",
    "# - Enhanced strategy (with your improvements)\n",
    "# Create comparison showing:\n",
    "# - Total return\n",
    "# - Sharpe ratio\n",
    "# - Max drawdown\n",
    "# - Win rate\n",
    "# - Number of trades\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fda37",
   "metadata": {},
   "source": [
    "### Analysis Questions for Task 3\n",
    "\n",
    "**TODO: Write your analysis here**\n",
    "\n",
    "1. Which enhancement(s) improved performance the most?\n",
    "2. Did enhancements reduce risk (drawdown, volatility)?\n",
    "3. How did enhancements affect the number of trades?\n",
    "4. What's the trade-off between complexity and robustness?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2722e7c2",
   "metadata": {},
   "source": [
    "## Task 4 (Advanced/Optional): Market-Neutral Portfolio\n",
    "\n",
    "**Objective:** Construct a market-neutral portfolio with target beta = 0.\n",
    "\n",
    "Combine long and short positions to eliminate market exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement market-neutral portfolio construction\n",
    "# 1. Calculate individual asset betas vs market\n",
    "# 2. Optimize portfolio with constraint: portfolio_beta = 0\n",
    "# 3. Allow both long and short positions\n",
    "# 4. Compare with long-only optimal portfolio\n",
    "\n",
    "# Hint: Add nonlinear constraint for beta\n",
    "# beta_constraint = {'type': 'eq', 'fun': lambda w: portfolio_beta(w) - 0}\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee93ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Backtest market-neutral portfolio\n",
    "# 1. Calculate portfolio returns\n",
    "# 2. Calculate market returns\n",
    "# 3. Show that portfolio is uncorrelated with market\n",
    "# 4. Compare performance in up/down markets\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172e7a97",
   "metadata": {},
   "source": [
    "**Analysis for Task 4:**\n",
    "\n",
    "**TODO: Write your analysis**\n",
    "\n",
    "1. What does the market-neutral portfolio look like (long/short positions)?\n",
    "2. Is the beta truly zero? Check correlation with market.\n",
    "3. How does performance compare in different market regimes?\n",
    "4. What are the practical challenges of running market-neutral strategies?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adec9c6",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Your completed notebook should include:\n",
    "\n",
    "- [ ] **Task 1 completed** - Constrained optimization with ≥2 variants\n",
    "- [ ] **Task 2 completed** - Rolling cointegration analysis\n",
    "- [ ] **Task 3 completed** - Enhanced pairs trading with ≥2 improvements\n",
    "- [ ] **At least 5 visualizations** - Efficient frontiers, z-scores, performance plots\n",
    "- [ ] **Performance comparison tables** - Clear metrics for all variants\n",
    "- [ ] **Written analysis** (5-8 paragraphs) addressing all questions\n",
    "- [ ] **Code comments** explaining implementation choices\n",
    "- [ ] **Conclusions** about practical applicability\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e3466",
   "metadata": {},
   "source": [
    "## Final Summary & Reflection\n",
    "\n",
    "**TODO: Write your comprehensive summary here (5-8 paragraphs)**\n",
    "\n",
    "Your summary should address:\n",
    "\n",
    "1. **Portfolio Optimization Insights:**\n",
    "   - How did adding constraints change optimal portfolios?\n",
    "   - Is the historical optimal portfolio likely to be optimal going forward?\n",
    "   - What are the practical limitations of mean-variance optimization?\n",
    "   - How would you implement this in production?\n",
    "\n",
    "2. **Cointegration Discoveries:**\n",
    "   - Which pairs showed the strongest cointegration?\n",
    "   - Did cointegration relationships remain stable over time?\n",
    "   - What causes cointegration to break down?\n",
    "   - How would you monitor cointegration in real-time?\n",
    "\n",
    "3. **Beta & Risk Management:**\n",
    "   - What role does beta play in portfolio construction?\n",
    "   - How can you use beta for hedging?\n",
    "   - Is market-neutrality always desirable?\n",
    "   - What are alternatives to beta for measuring risk?\n",
    "\n",
    "4. **Pairs Trading Performance:**\n",
    "   - Did your enhanced strategy outperform the baseline?\n",
    "   - What were the main sources of improvement (or deterioration)?\n",
    "   - How sensitive is the strategy to parameter choices?\n",
    "   - What market conditions favor pairs trading?\n",
    "\n",
    "5. **Integration & Practical Application:**\n",
    "   - How would you combine these techniques in a real trading system?\n",
    "   - What additional data or tools would you need?\n",
    "   - What are the main risks and how would you mitigate them?\n",
    "   - Which technique (optimization, cointegration, or beta analysis) is most valuable?\n",
    "\n",
    "6. **Comparison with Previous Methods:**\n",
    "   - How does portfolio optimization compare to equal-weighting?\n",
    "   - How does statistical arbitrage compare to momentum/trend strategies?\n",
    "   - When would you use each approach?\n",
    "\n",
    "7. **Key Learnings:**\n",
    "   - What surprised you most in your experiments?\n",
    "   - What would you do differently with more time/data?\n",
    "   - How do these advanced techniques fit into the bigger picture of quantitative trading?\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:** These are sophisticated techniques used by professional quantitative traders and hedge funds. Success requires:\n",
    "- Rigorous backtesting with out-of-sample validation\n",
    "- Careful risk management and position sizing\n",
    "- Continuous monitoring and adjustment\n",
    "- Understanding of market microstructure and costs\n",
    "\n",
    "Focus on building intuition for when and why these methods work, not just on achieving high backtest returns. 🚀"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
